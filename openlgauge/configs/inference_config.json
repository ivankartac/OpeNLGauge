{
    "max_seq_length": 4096,
    "max_new_tokens": 1536,
    "temperature": 0.0,
    "do_sample": false,
    "device": "cuda",
    "retry_config": {
        "max_retries": 3,
        "temperature": 0.1,
        "top_p": 0.95,
        "do_sample": true
    }
}