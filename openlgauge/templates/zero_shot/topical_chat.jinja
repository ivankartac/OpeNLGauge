### Instructions
Your task is to evaluate an output of dialogue response generation task, where dialogue participants are discussing interesting topics, facts and trivia.
{% if include_source %}Based on the given dialogue history and the generated response, identify errors in the response with respect to {{ aspect_name }} (described below).{% elif include_knowledge %}Based on the given context knowledge and the generated response, identify errors in the response with respect to {{ aspect_name }} (described below).{% else %}Identify errors in the generated response with respect to {{ aspect_name }} (described below).{% endif %}
For each error, determine its severity on a scale from 1 to 5, where 1 is the least severe and 5 is the most severe.

Definition of {{ aspect_name|capitalize }}:
{{ aspect_definition }}

Rules:
Do not make assumptions or bring in external knowledge not present in the provided context.
Identify only the errors related to {{ aspect_name }} of the response. Do not consider other aspects such as {{ negative_aspect_examples|join(' or ') }}!
If there are no errors related to {{ aspect_name }} in the response, you should output 'No Error' and provide 'Excellent' score.
{% if extra_rules %}{{ join('\n')|extra_rules }}{% endif %}

Steps:
{% for step in steps -%}
{{ loop.index }}. {{ step }}
{% endfor %}
{% for key, value in inputs.items() -%}
{% if value and include_source and key == 'Dialogue history' %}
### {{ key }}
{{ value }}
{% elif value and include_knowledge and key == 'Knowledge' %}
### {{ key }}
{{ value }}
{% endif %}
{% endfor %}
{% for key, value in outputs.items() -%}
### {{ key }}
{{ value }}
{% endfor %}

### Output format:
Generate your output exactly in this format:
```
Error 1:
Location: <location of the error - the exact word or phrase in the response>
Explanation: <explanation for the error, including the reason why it is considered {{ aspect_name }} issue>
Severity: <integer from 1 to 5>

Error 2:
...

Overall score: <one of: Unacceptable, Poor, Fair, Good, Excellent>
Explanation of the score: <explanation of the score>
```